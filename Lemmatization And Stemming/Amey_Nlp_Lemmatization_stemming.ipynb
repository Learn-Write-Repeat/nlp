{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gd1m3y/Open-contributions/blob/master/Amey_nlp_Lemmatization_stemming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uwBbeZC9M0Df"
   },
   "source": [
    "# Lemmatization and Stemming in NLTK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XhsgC5YLM8UR"
   },
   "source": [
    "## Imports\n",
    "*we assume that the reader has basic Knowledge of Python syntaxes and Jupter notebook enviorment*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t-6J15rnNd5M"
   },
   "source": [
    "## nltk\n",
    "nltk or Natural language toolkit is a collection of libraries and program for statistical natural language processing in python language\n",
    "\n",
    "we will begin by installing the library using pip command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "eFb56x-g56Gf",
    "outputId": "727797b0-85a8-4cd2-abce-6f4b81809ff8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\aditya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aditya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (4.46.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\aditya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (0.14.1)\n",
      "Requirement already satisfied: regex in c:\\users\\aditya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (2020.6.8)\n",
      "Requirement already satisfied: click in c:\\users\\aditya\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from nltk) (7.1.2)\n"
     ]
    }
   ],
   "source": [
    "#first we will install the nltk library\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QX9ddxYINXaQ"
   },
   "outputs": [],
   "source": [
    "import nltk \n",
    "# nltk.download('all')\n",
    "import string\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w9NMTdZWOGS3"
   },
   "source": [
    "# Stemming\n",
    "\n",
    "\"Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language.\"\n",
    "\n",
    "There are 3 types of major stemming techniques-\n",
    "\n",
    "1.Porter Stemmer\n",
    "\n",
    "2.Lancaster Stemmer\n",
    "\n",
    "3.SnowBall Stemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "RuAQb0J0Ndcg",
    "outputId": "4a20dede-4fd2-469a-8371-4698ff7e58fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Word : writing \n",
      "Stemmed Word : write\n",
      "Orginal Word : running \n",
      "Stemmed Word : run\n",
      "Orginal Word : walked \n",
      "Stemmed Word : walk\n",
      "Orginal Word : loving \n",
      "Stemmed Word : love\n",
      "Orginal Word : caring \n",
      "Stemmed Word : care\n"
     ]
    }
   ],
   "source": [
    "# porter stemming\n",
    "\n",
    "#importing PorterStemmer class from ntlk.stem\n",
    "from nltk.stem import PorterStemmer\n",
    "word_stemmer = PorterStemmer()\n",
    "word = ['writing','running','walked','loving','caring']\n",
    "for i in word:\n",
    "  result = word_stemmer.stem(i)\n",
    "\n",
    "  print(f'Orginal Word : {i} \\nStemmed Word : {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "mcNmwymvP9mo",
    "outputId": "26b014c8-4554-403e-b36f-9c84cefc71a4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Word : writing \n",
      "Stemmed Word : writ\n",
      "Orginal Word : running \n",
      "Stemmed Word : run\n",
      "Orginal Word : walked \n",
      "Stemmed Word : walk\n",
      "Orginal Word : loving \n",
      "Stemmed Word : lov\n",
      "Orginal Word : caring \n",
      "Stemmed Word : car\n"
     ]
    }
   ],
   "source": [
    "#importing Lancaster Stemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "Lanc_stemmer = LancasterStemmer()\n",
    "word = ['writing','running','walked','loving','caring']\n",
    "for i in word:\n",
    "  result = Lanc_stemmer.stem(i)\n",
    "# we can see some words like love are taken as lov which dont have any meaning\n",
    "  print(f'Orginal Word : {i} \\nStemmed Word : {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "_ikWZA5uRovw",
    "outputId": "dcb1a46c-d80e-478c-b0f2-8c928ddb25c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#snowball stemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "#before using SnowballStemer we have to mention the particular language we are going to feed it\n",
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "Zkn7agFiTIJ0",
    "outputId": "57a8148c-94b2-42d7-b794-48069e9e6781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Word : writing \n",
      "Stemmed Word : write\n",
      "Orginal Word : running \n",
      "Stemmed Word : run\n",
      "Orginal Word : walked \n",
      "Stemmed Word : walk\n",
      "Orginal Word : loving \n",
      "Stemmed Word : love\n",
      "Orginal Word : caring \n",
      "Stemmed Word : care\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SnowballStemmer('english')\n",
    "word = ['writing','running','walked','loving','caring']\n",
    "for i in word:\n",
    "  result = model.stem(i)\n",
    "# we can see some words like love are taken as lov which dont have any meaning\n",
    "  print(f'Orginal Word : {i} \\nStemmed Word : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y54uabX3Tt0R"
   },
   "source": [
    "# Lemmatizatizer\n",
    "Lemmatization, unlike Stemming, reduces the inflected words properly ensuring that the root word belongs to the language. In Lemmatization root word is called Lemma. A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "6VTQSD7QTo_l",
    "outputId": "a58e40fb-34d7-41c3-b2b4-03a1eadcd971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orginal Word : books \n",
      "Stemmed Word : book\n",
      "Orginal Word : cooks \n",
      "Stemmed Word : cook\n",
      "Orginal Word : shooks \n",
      "Stemmed Word : shook\n",
      "Orginal Word : loves \n",
      "Stemmed Word : love\n",
      "Orginal Word : gazes \n",
      "Stemmed Word : gaze\n"
     ]
    }
   ],
   "source": [
    "#importing the WordNetLemmatizer class nltk.stem class\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "word = ['books','cooks','shooks','loves','gazes']\n",
    "for i in word:\n",
    "  result = lemmatizer.lemmatize(i)\n",
    "  print(f'Orginal Word : {i} \\nStemmed Word : {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2w6UMs4NVON1"
   },
   "source": [
    "#Lemmatization vs Stemming\n",
    "\n",
    "The major difference between both is that Lemmatization tries to find the root word rather than the root stem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1QYvoApgUTwK",
    "outputId": "4c757860-f9cb-4a9d-fc1e-cc0fdd16aeac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'believ'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_stemmer = PorterStemmer()\n",
    "word_stemmer.stem('believes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "WmFRXlkOV61W",
    "outputId": "52e5549e-601e-4098-e19a-a0ba684ff82a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' believes '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatizer.lemmatize(' believes ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mxIbumWWDMN"
   },
   "source": [
    "### **The output of both programs tells the major difference between stemming and lemmatization. PorterStemmer class chops off the ‘es’ from the word. On the other hand, WordNetLemmatizer class finds a valid word. In simple words, stemming technique only looks at the form of the word whereas lemmatization technique looks at the meaning of the word. It means after applying lemmatization, we will always get a valid word.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BiZXgJP3V9MS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNR4kG+mkyp0gn1+zFT7MDq",
   "include_colab_link": true,
   "name": "Amey_nlp_Lemmatization_stemming.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
